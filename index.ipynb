{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data Using Pandas - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll get some practice with loading files with summary or metadata, and if you find that easy, the optional \"level up\" content covers loading data from a currupted csv file!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "You will be able to:\n",
    "* Import data from csv files and Excel files\n",
    "* Understand and explain key arguments for imports\n",
    "* Save information to csv and Excel files\n",
    "* Access data within a Pandas DataFrame (print() and .head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Loading Files with Summary or Meta Data\n",
    "\n",
    "Load either of the files Zipcode_Demos.csv or Zipcode_Demos.xlsx. What's going on with this dataset? Clean it up into a useable format and describe the nuances of how the data is currently formatted.\n",
    "\n",
    "All data files are stored in a folder titled 'Data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_data = pd.read_csv('Data/Zipcode_Demos.csv')\n",
    "zipcode_data.head()\n",
    "zipcode_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = zipcode_data.drop(list(range(0,46)))\n",
    "#there was a dataframe atop another. had to get rid of the descriptive one, since its values \n",
    "#were NAN\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.iloc[1]) # this locates the column with index specified in [ ] .isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up (Optional)\n",
    "\n",
    "### Loading Corrupt CSV files\n",
    "\n",
    "Occassionally, you encountered some really ill formatted data. One example of this can be data that has strings containing commas in a csv file. Under the standard protocol, when this occurs, one is suppossed to use quotes to differentiate between the commas denoting fields and commas within those fields themselves. For example, we could have a table like this:  \n",
    "\n",
    "ReviewerID,Rating,N_reviews,Review,VenueID\n",
    "123456,4,137,This restuarant was pretty good, we had a great time.,98765\n",
    "\n",
    "Which should be saved like this if it were a csv (to avoid confusion with the commas in the Review text):\n",
    "\"ReviewerID\",\"Rating\",\"N_reviews\",\"Review\",\"VenueID\"\n",
    "\"123456\",\"4\",\"137\",\"This restuarant was pretty good, we had a great time.\",\"98765\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to import the corrupt file, or at least a small preview of it. It is appropriately titled Yelp_Reviews_corrupt.csv. Investigate some of the intricacies of skipping rows to then pass over this error and comment on what you think is going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hint: here's a useful programming pattern to use.\n",
    "try:\n",
    "    pd.read_csv('Data/Yelp_Reviews_corrupt.csv', delimiter=',').head()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1500,2000):\n",
    "    try:\n",
    "        df = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', nrows=i) #try to read all rows up to ith row\n",
    "    except:\n",
    "        print('failure at: {}'.format(i)) #it's going to fail at some point, find it\n",
    "        break\n",
    "df1 = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', nrows=i-1) #print all the data, up until the breaking ith row\n",
    "print(len(df))\n",
    "df1.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iteration 2 \n",
    "for i in range(0,500):\n",
    "    try:\n",
    "        temp = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', skiprows=1962, nrows=i, names=df1.columns)\n",
    "    #we know from first iteration that it broke at 1961, so look at 1962 and forward\n",
    "    #add the names of the df1, by using .columns\n",
    "    except:\n",
    "        print('First failure at: {}'.format(i))\n",
    "        break\n",
    "df2 = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', skiprows=1962, nrows=i-1, names=df1.columns)\n",
    "print(len(df2))\n",
    "df2.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv')\n",
    "print(len(temp))\n",
    "temp.head()\n",
    "# this wont work, because...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pomGBqfbxcqPv14c3XH-ZQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2012-11-13</td>\n",
       "      <td>0</td>\n",
       "      <td>dDl8zu1vWPdKGihJrwQbpw</td>\n",
       "      <td>5</td>\n",
       "      <td>I love this place! My fiance And I go here atl...</td>\n",
       "      <td>0</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>jtQARsP6P-LbkyjbO1qNGg</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-23</td>\n",
       "      <td>1</td>\n",
       "      <td>LZp4UX5zK3e-c5ZGSeo3kA</td>\n",
       "      <td>1</td>\n",
       "      <td>Terrible. Dry corn bread. Rib tips were all fa...</td>\n",
       "      <td>3</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Ums3gaP2qM3W1XcA5r6SsQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-05</td>\n",
       "      <td>0</td>\n",
       "      <td>jsDu6QEJHbwP2Blom1PLCA</td>\n",
       "      <td>5</td>\n",
       "      <td>Delicious healthy food. The steak is amazing. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>vgfcTvK81oD4r50NMjU2Ag</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-02-25</td>\n",
       "      <td>0</td>\n",
       "      <td>pfavA0hr3nyqO61oupj-lA</td>\n",
       "      <td>1</td>\n",
       "      <td>This place sucks. The customer service is horr...</td>\n",
       "      <td>2</td>\n",
       "      <td>msQe1u7Z_XuqjGoqhB0J5g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>yFumR3CWzpfvTH2FCthvVw</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-06-15</td>\n",
       "      <td>0</td>\n",
       "      <td>STiFMww2z31siPY7BWNC2g</td>\n",
       "      <td>5</td>\n",
       "      <td>I have been an Emerald Club member for a numbe...</td>\n",
       "      <td>0</td>\n",
       "      <td>TlvV-xJhmh7LCwJYXkV-cg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0             business_id cool        date funny  \\\n",
       "0          1  pomGBqfbxcqPv14c3XH-ZQ    0  2012-11-13     0   \n",
       "1          2  jtQARsP6P-LbkyjbO1qNGg    1  2014-10-23     1   \n",
       "2          4  Ums3gaP2qM3W1XcA5r6SsQ    0  2014-09-05     0   \n",
       "3          5  vgfcTvK81oD4r50NMjU2Ag    0  2011-02-25     0   \n",
       "4         10  yFumR3CWzpfvTH2FCthvVw    0  2016-06-15     0   \n",
       "\n",
       "                review_id stars  \\\n",
       "0  dDl8zu1vWPdKGihJrwQbpw     5   \n",
       "1  LZp4UX5zK3e-c5ZGSeo3kA     1   \n",
       "2  jsDu6QEJHbwP2Blom1PLCA     5   \n",
       "3  pfavA0hr3nyqO61oupj-lA     1   \n",
       "4  STiFMww2z31siPY7BWNC2g     5   \n",
       "\n",
       "                                                text useful  \\\n",
       "0  I love this place! My fiance And I go here atl...      0   \n",
       "1  Terrible. Dry corn bread. Rib tips were all fa...      3   \n",
       "2  Delicious healthy food. The steak is amazing. ...      0   \n",
       "3  This place sucks. The customer service is horr...      2   \n",
       "4  I have been an Emerald Club member for a numbe...      0   \n",
       "\n",
       "                  user_id  \n",
       "0  msQe1u7Z_XuqjGoqhB0J5g  \n",
       "1  msQe1u7Z_XuqjGoqhB0J5g  \n",
       "2  msQe1u7Z_XuqjGoqhB0J5g  \n",
       "3  msQe1u7Z_XuqjGoqhB0J5g  \n",
       "4  TlvV-xJhmh7LCwJYXkV-cg  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = pd.read_csv('Data/Yelp_Reviews_Corrupt.csv', names=df1.columns, skiprows=1)\n",
    "print(len(temp))\n",
    "temp.head()\n",
    "#but this will work.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
